{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-28T16:14:43.064033Z","iopub.execute_input":"2021-10-28T16:14:43.064346Z","iopub.status.idle":"2021-10-28T16:14:43.0706Z","shell.execute_reply.started":"2021-10-28T16:14:43.064313Z","shell.execute_reply":"2021-10-28T16:14:43.069919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:14:43.072512Z","iopub.execute_input":"2021-10-28T16:14:43.073176Z","iopub.status.idle":"2021-10-28T16:14:43.084515Z","shell.execute_reply.started":"2021-10-28T16:14:43.073142Z","shell.execute_reply":"2021-10-28T16:14:43.083671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import Tensor\nimport torch.nn as nn\nfrom torch.nn.modules import linear\nfrom torchvision import models\n\nclass Lenet(nn.Module):\n    def __init__(self, n_classes=10, dropout=0.2):\n        super(Lenet, self).__init__()\n\n        self.n_classes = n_classes\n        self.convolution = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5), #28*28*6\n            nn.Tanh(),\n            nn.AvgPool2d(kernel_size=2, padding=0), #14*14*6\n            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5), #10 * 10* 16\n            nn.Tanh(),\n            nn.AvgPool2d(kernel_size=2, padding=0), # 5*5*16\n            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5), #1*1*120\n            nn.Tanh(),\n        )\n        self.linear = nn.Sequential(\n            nn.Linear(120, 84),\n            nn.Tanh(),\n            nn.Linear(84, n_classes),\n            nn.Dropout(dropout)\n        )\n    \n    def forward(self, images: Tensor):\n        \"\"\"\n        input:\n            images: batch_size * 3 *32 *32 \n        \n        outptu:\n            tensor: batch_size * n_classes\n        \"\"\"\n        outputs = self.convolution(images)\n        outputs = outputs.reshape(outputs.size(0), -1)\n        return self.linear(outputs)\n\n\nclass Alexnet(nn.Module):\n    def __init__(self, n_classes:int = 10,\n                 dropout:float = 0.2,\n                 use_pretrained: bool = False\n        ):\n        super(Alexnet, self).__init__()\n        self.n_classes = n_classes\n        self.use_pretrained = use_pretrained\n        if not self.use_pretrained:\n            self.convolution = nn.Sequential(\n                nn.Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n                nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n                nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n            )\n            self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n            self.linear = nn.Sequential(\n                nn.Dropout(p=dropout),\n                nn.Linear(256 * 6 * 6, 4096),\n                nn.ReLU(inplace=True),\n                nn.Dropout(p=dropout),\n                nn.Linear(4096, 4096),\n                nn.ReLU(inplace=True),\n                nn.Linear(4096, n_classes),\n            )\n        else:\n            alexnet = models.alexnet(pretrained=True)\n            convolution_layers = list(alexnet.children())[:-1]\n            linear_layers = list(alexnet.children())[-1][:-2]\n            self.convolution = nn.Sequential(*convolution_layers)\n            self.linear1 = nn.Sequential(*linear_layers)\n            for param in self.convolution.parameters():\n                param.requires_grad = False\n            \n            for param in self.linear1.parameters():\n                param.requires_grad = False\n\n            self.linear = nn.Linear(4096, 10)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, images):\n        if not self.use_pretrained:\n            outs = self.convolution(images)\n            outs = self.avgpool(outs)\n            outs = outs.reshape(outs.size(0), -1)\n        else:\n            outs = self.convolution(images)\n            outs = outs.reshape(outs.size(0), -1)\n            outs = self.linear1(outs)\n        return self.linear(self.dropout(outs))\n        \n\n        ","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:14:43.085759Z","iopub.execute_input":"2021-10-28T16:14:43.086077Z","iopub.status.idle":"2021-10-28T16:14:43.112629Z","shell.execute_reply.started":"2021-10-28T16:14:43.086043Z","shell.execute_reply":"2021-10-28T16:14:43.111798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model_name: str,\n                batch_size: int = 64,\n                lr: float = 1e-5,\n                path_save_model: str = \"\",\n                n_epochs: int = 100,\n                use_pretrained: float = False,\n                training_data_percent:float = 0.2\n        ):\n        self.model_name = model_name\n        self.n_classes = 10\n        self.batch_size = batch_size\n        self.lr = lr \n        self.use_pretrained = use_pretrained\n        self.training_data_percent = training_data_percent\n        self.path_save_model = path_save_model\n        self.n_epochs = n_epochs \n        self.loss_fn = nn.CrossEntropyLoss()\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model = self.get_model()\n        self.optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n        self.acc_test_current = 0\n        self.make_loader()\n    \n    def get_model(self):\n        if self.model_name == \"lenet\":\n            model = Lenet(n_classes=self.n_classes).to(self.device)\n            self.input_size = 32\n\n        elif self.model_name ==\"alexnet\":\n            model = Alexnet(n_classes=self.n_classes, use_pretrained = self.use_pretrained).to(self.device)\n            self.input_size = 224\n        else:\n            raise Exception(\"Not implement\")\n\n        return model\n    \n    def make_loader(self):\n        self.transform = transforms.Compose([\n            transforms.Resize(self.input_size),\n            transforms.ToTensor(),\n            transforms.Normalize((0.1307,), (0.3081,))\n        ])\n        self.train_set = torchvision.datasets.MNIST(root='./data', \n                                            train=True, \n                                            download=True,\n                                            transform=self.transform\n                                        )\n        self.test_set = torchvision.datasets.MNIST(root='./data',\n                                        train=False,\n                                        download=True,\n                                        transform=self.transform\n                                        )\n        self.n_train_samples = int(self.training_data_percent * len(self.train_set))\n        self.n_val_samples = len(self.train_set) - self.n_train_samples\n        self.train_set, self.val_set = random_split(\n            self.train_set,\n            lengths=[self.n_train_samples, self.n_val_samples],\n            generator=torch.Generator().manual_seed(42),\n        )\n        self.train_loader = DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True,num_workers=2)\n        self.val_loader = DataLoader(self.val_set, batch_size=self.batch_size, shuffle=True,num_workers=2)\n        self.test_loader = DataLoader(self.test_set, batch_size=self.batch_size, shuffle=False, num_workers=2)\n\n\n    def train_on_epoch(self):\n        self.model.train()\n        train_loss = 0\n        correct, total = 0, 0\n        for idx,(images, labels) in enumerate(self.train_loader):\n            images = images.to(self.device)\n            labels = labels.to(self.device)\n            outs = self.model(images)\n            self.optimizer.zero_grad()\n            loss = self.loss_fn(outs, labels)\n            loss.backward()\n            self.optimizer.step()\n            \n            predict = torch.argmax(outs, dim=1)\n            total += predict.size(0)\n            correct += (predict == labels).sum().item()\n            train_loss += loss.item()\n            \n            if idx % 200 == 0:\n                print(idx, end=\" \")\n        print()\n        return train_loss/len(self.train_loader), correct / total\n    \n    def plot(self, title, file_name, train_values, val_values,is_acc=False):\n        plt.plot(range(len(train_values)),train_values)\n        plt.plot(range(len(train_values)),val_values)\n        plt.title(title)\n        if is_acc:\n            plt.ylabel(\"Accuracy\")\n        else:\n            plt.ylabel(\"Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.legend(['Train', 'Val'])\n        plt.show()\n        plt.savefig(file_name)\n\n    def plot_history(self):\n        self.plot('Accuracy', 'acc.png', self.history['train_acc'], self.history['val_acc'], is_acc=True)\n        self.plot('Loss', 'loss.png', self.history['train_loss'], self.history['val_loss'])\n\n    def save_model(self, epoch):\n        model_state ={\n            \"model\" : self.model.state_dict(),\n            \"optimizer\" : self.optimizer\n        }\n        torch.save(model_state, self.path_save_model+f'model{epoch}.pth')\n        print(\"Save model done\")\n        with open(f\"history{epoch}.pkl\",'wb') as file:\n            pickle.dump(self.history, file, protocol=pickle.HIGHEST_PROTOCOL)\n        print(\"Save history done\")\n    \n    def testing(self):\n        correct, total = 0, 0\n        with torch.no_grad():\n            for images, labels in self.test_loader:\n                images = images.to(self.device)\n                labels = labels.to(self.device)\n                outs = self.model(images)\n                \n                predict = torch.argmax(outs, dim=1)\n                total += predict.size(0)\n                correct += (predict == labels).sum().item()\n        \n        self.acc_test_current = 100 * correct / total\n        print(\"Accuracy for testing: {:.2f}\\n\".format(self.acc_test_current))\n\n    def evaluate(self):\n        val_loss = 0\n        self.model.eval()\n        correct, total = 0, 0\n        for idx,(images, labels) in enumerate(self.val_loader):\n            images = images.to(self.device)\n            labels = labels.to(self.device)\n            outs = self.model(images)\n            loss = self.loss_fn(outs, labels)\n            val_loss += loss.item()\n            \n            predict = torch.argmax(outs, dim=1)\n            total += predict.size(0)\n            correct += (predict == labels).sum().item()\n            if idx % 200 == 0:\n                print(idx, end=\" \")\n        print()\n        return val_loss/len(self.val_loader), correct / total\n    \n\n    def fit(self):\n        self.history = defaultdict(list)\n        best_acc = 0\n        for epoch in range(self.n_epochs):\n            start_time = time.time()\n            train_loss, train_acc = self.train_on_epoch()\n            val_loss, val_acc = self.evaluate()\n            self.history['train_acc'].append(train_acc)\n            self.history['train_loss'].append(train_loss)\n            self.history['val_acc'].append(val_acc)\n            self.history['val_loss'].append(val_loss)\n            print(f\"Epoch:{epoch}---Train acc:{train_acc}---Train loss:{train_loss}---Val acc:{val_acc}---Val loss:{val_loss}--Time:{time.time()-start_time}\")            \n            self.testing()\n            if self.acc_test_current > best_acc and epoch >= 120:\n                best_acc = self.acc_test_current \n                self.save_model(epoch)\n                \n","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:14:43.114725Z","iopub.execute_input":"2021-10-28T16:14:43.114999Z","iopub.status.idle":"2021-10-28T16:14:43.153605Z","shell.execute_reply.started":"2021-10-28T16:14:43.114964Z","shell.execute_reply":"2021-10-28T16:14:43.152836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model_name='lenet',\n    lr=1e-2,\n    n_epochs=500,\n    batch_size=256,\n    use_pretrained=False,\n    training_data_percent=0.9\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:14:43.154823Z","iopub.execute_input":"2021-10-28T16:14:43.155179Z","iopub.status.idle":"2021-10-28T16:14:44.703101Z","shell.execute_reply.started":"2021-10-28T16:14:43.155143Z","shell.execute_reply":"2021-10-28T16:14:44.702358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(trainer.train_loader))","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:14:44.704289Z","iopub.execute_input":"2021-10-28T16:14:44.704653Z","iopub.status.idle":"2021-10-28T16:14:44.71179Z","shell.execute_reply.started":"2021-10-28T16:14:44.704604Z","shell.execute_reply":"2021-10-28T16:14:44.708845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(trainer.val_loader))","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:14:44.714159Z","iopub.execute_input":"2021-10-28T16:14:44.715076Z","iopub.status.idle":"2021-10-28T16:14:44.720417Z","shell.execute_reply.started":"2021-10-28T16:14:44.715034Z","shell.execute_reply":"2021-10-28T16:14:44.71978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:14:44.721791Z","iopub.execute_input":"2021-10-28T16:14:44.722196Z","iopub.status.idle":"2021-10-28T17:10:07.967025Z","shell.execute_reply.started":"2021-10-28T16:14:44.722159Z","shell.execute_reply":"2021-10-28T17:10:07.965572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}